{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad6061b-8baa-4ab4-add0-db674cf11620",
   "metadata": {},
   "source": [
    "# **AT&T Spam Detector**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Contents\n",
    "--------\n",
    "1. [Data loading and preprocessing](#loading)\n",
    "2. [Preliminary data analysis](#eda)\n",
    "3. [Benchmarking with a logistic regression](#logreg)\n",
    "4. [A first neural network: Multi-layer perceptron and TF-IDF](#tfidf-mlp)\n",
    "4. [Gated Recurrent Units with character tokens](#gru-char)\n",
    "4. [Gated Recurrent Units with word tokens](#gru-word)\n",
    "4. [Conclusion and perspectives](#conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1811f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330265c",
   "metadata": {},
   "source": [
    "## <a id=\"loading\"></a> Data loading and preprocessing\n",
    "\n",
    "The dataset consists of 5574 entries, many of which have issues. Here is a non-exhaustive list:\n",
    "- The file doesn't decode as `UTF-8`. It must be decoded as `latin-1` or `mac-roman`.\n",
    "- Some rows are ill-formed (eg line 101 of the csv: `ham\"\"\",,,`)\n",
    "- Most rows have trailing commas\n",
    "- Some messages are anclosed in (possibly many) double quote characters\n",
    "- Single and double quotes are escaped with backslashes\n",
    "- Some spurious characters are present (eg `å` characters that systematically prepend pound symbols `£`)\n",
    "\n",
    "Fortunately, the original version of the dataset can be found [here](https://archive.ics.uci.edu/dataset/228/sms+spam+collection). Its entries are much cleaner than those of our dataset. We can use them as a comparison to setup the cleaning and processing for our dataset:\n",
    "- Strip the trailing commas\n",
    "- Completely remove the double quotes `\"`\n",
    "- Convert backslashes + single quote `\\'` into single quote `'`\n",
    "- Convert backslashes `\\` into double quotes `\"`\n",
    "- Remove the spurious characters `å`\n",
    "\n",
    "The implementation of this pipeline is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Loading and preprocessing the project dataset ##########\n",
    "with open('./spam.csv', 'rt', encoding='latin-1') as f:\n",
    "    f.readline() # remove header\n",
    "    raw_data = [row.strip().split(',', 1) for row in f.readlines()]\n",
    "\n",
    "## set target\n",
    "is_spam = np.array([True if row[0] == 'spam' else False for row in raw_data])\n",
    "\n",
    "## process and clean messages\n",
    "messages = [row[1].strip(',') \\\n",
    "                  .replace('\"', '') \\\n",
    "                  .replace(\"\\\\'\", \"'\") \\\n",
    "                  .replace('\\\\', '\"') \\\n",
    "                  .replace('å', '')\n",
    "            for row in raw_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1f96f",
   "metadata": {},
   "source": [
    "However, some encoding issues persist with some problematic characters still present in messages. To proceed with the project we will rather use this original dataset as the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c04177",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Loading and preprocessing the original dataset ##########\n",
    "with open('./SMSSpamCollection', 'rt', encoding='utf-8') as f:\n",
    "    raw_data = [row.strip().split('\\t', 1) for row in f.readlines()]\n",
    "\n",
    "is_spam = np.array([True if row[0] == 'spam' else False for row in raw_data])\n",
    "messages = np.array([row[1] for row in raw_data], dtype=object)\n",
    "\n",
    "df = pd.DataFrame({'message': messages, 'is_spam': is_spam})\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb955c59",
   "metadata": {},
   "source": [
    "Our dataset seems to have duplicates. We choose not to remove them, they certainly represent frequent messages for which making a classification error should be penalized more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25683080",
   "metadata": {},
   "source": [
    "## <a id=\"eda\"></a> Preliminary data analysis\n",
    "\n",
    "The messages are quite complex, mixing  uppercase, lowercase, puctuation, alphanumeric and other exotic characters.\n",
    "Training a model to the data would certainly require some form of text normalization. However, this might cause a loss\n",
    "of information. In this section we try to somewhat keep this information and aggregate it in the form of a few descriptive\n",
    "to get insight about what makes a message a spam.\n",
    "\n",
    "An important remark is in order before proceeding with data analysis. Visual inspection of the dataset reveals\n",
    "the presence of some tokens specific to ham messages: `<#>`, `<DECIMAL>`, `<TIME>` and `<URL>`\n",
    "(they appear as `&lt;*&gt;` in the dataset).\n",
    "These were certainly introduced to mask personal information from hams. Although the kind of values that\n",
    "`<DECIMAL>`, `<TIME>` and `<URL>` replace is obvious, this is not the case for `<#>`, which seems to be used\n",
    "in replacement of any kind of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.DataFrame(\n",
    "    {'is_spam': df['is_spam'],\n",
    "     'count_<#>': df['message'].map(lambda x: x.count('<#>')),\n",
    "     'count_<DECIMAL>': df['message'].map(lambda x: x.count('<DECIMAL>')),\n",
    "     'count_<TIME>': df['message'].map(lambda x: x.count('<TIME>')),\n",
    "     'count_<URL>': df['message'].map(lambda x: x.count('<URL>'))})\n",
    "\n",
    "tokens_df.groupby('is_spam').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8e2e9",
   "metadata": {},
   "source": [
    "## <a id=\"eda\"></a> Preliminary data analysis\n",
    "\n",
    "Indeed, these tokens are specific to hams. There presence, due to human annotations, could introduce\n",
    "important biases to an automated detection system if not handled properly.\n",
    "\n",
    "With this remark in mind, we can move to the characterization of messages using the following descriptive features:\n",
    "- `msg_len`, the length of the message;\n",
    "- `chr_caps`, the number of capitallized characters;\n",
    "- `chr_digit`, the number of digit characters in the message;\n",
    "- `chr_punct`, the number of punctuation characters in the message;\n",
    "- `max_wd_len`, he length of the longest character string (split by whitespaces);\n",
    "- `lex_money`, the number of some money-related words and characters: `'$'`, `'£'`, `'€'`, `'cash'`, `'free'`, `'price'` and `'prize'`. The presence of these tokens indicates that the message talks about money (after all, spamming is about getting money from people). We could also consider adding words related to the lexical field of sex.\n",
    "- `caps_first`, the number of consecutive capitallized characters at the beginning of the message.\n",
    "\n",
    "For the purpose of data visualization, we remove the duplicates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cebbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define some helper functions\n",
    "def count_tokens(msgs: pd.DataFrame, tokens: list['str'])-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in the token list from the casefolded messages.\n",
    "    \"\"\"\n",
    "    regex = '|'.join(tokens)\n",
    "    return msgs.apply(lambda x: len(re.findall(regex, x.casefold())))\n",
    "    \n",
    "\n",
    "def count_first_caps(s: str)-> int:\n",
    "    \"\"\"\n",
    "    Count the number of capitallized letters at the beginning of a string.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for c in s:\n",
    "        if not c.isupper():\n",
    "            return n\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "def build_features(msgs: pd.DataFrame)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract quantitative features from a series of messages.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'msg_len': msgs.apply(len),\n",
    "        'chr_caps': msgs.apply(lambda s: sum(c.isupper() for c in s)),\n",
    "        'chr_digit': msgs.apply(lambda s: sum(c.isdigit() for c in s)),\n",
    "        'chr_punct': msgs.apply(lambda s: sum(c in punctuation for c in s)),\n",
    "        'max_wd_len': msgs.apply(lambda s: max(len(x) for x in s.split(' '))),\n",
    "        'lex_money': count_tokens(msgs, [r'\\$', '£', '€', 'free', 'cash', 'price', 'prize']),\n",
    "        'caps_first': msgs.apply(count_first_caps)\n",
    "        }\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15563bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare dataset from extracted features\n",
    "df_ = df.drop_duplicates()\n",
    "X = build_features(df_['message'])\n",
    "y = df_['is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spam = X.loc[y]\n",
    "X_spam.describe().applymap(lambda x: f\"{x:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ham = X.loc[~y]\n",
    "X_ham.describe().applymap(lambda x: f\"{x:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c978ad",
   "metadata": {},
   "source": [
    "Some of our derived features are actually quite discriminating for the spam/ham nature of the messages.\n",
    "- The number of digits is clearly the most discriminating feature with a mean of 15 for spams vs 0.3 for hams. 75 % of spams have more than 10 digits while less than 25% have a single digit.\n",
    "- The presence of money-related words 'free', 'cash' and currency characters is also discriminative of spams, although many spams do not have any.\n",
    "- Spams tend to also have larger message lengths, capitallized characters and punctuation characters. However, there is more overlap between the two categories in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1, v2 = 'chr_digit', 'max_wd_len'\n",
    "\n",
    "## number of hams with given values of `v1` and `v2`\n",
    "count_ham = X_ham.loc[:, [v1, v2]].value_counts()\n",
    "x_ham, y_ham = count_ham.index.to_frame().to_numpy().T\n",
    "\n",
    "## number of spams with given values of `v1` and `v2`\n",
    "count_spam = X_spam.loc[:, [v1, v2]].value_counts()\n",
    "x_spam, y_spam = count_spam.index.to_frame().to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(5.5, 4.8), dpi=200,\n",
    "    gridspec_kw={'left': 0.12, 'right': 0.92, 'top': 0.9, 'bottom': 0.10}\n",
    ")\n",
    "fig1.suptitle('Figure 1: Scatter plot of messages characteristics',\n",
    "              x=0.02, ha='left')\n",
    "\n",
    "sc_ham = ax1.scatter(x_ham, y_ham, count_ham+2,\n",
    "                     c='blue', alpha=0.65, marker='o', linewidths=0,\n",
    "                     label='hams')\n",
    "sc_spam = ax1.scatter(x_spam, y_spam, count_spam+2,\n",
    "                      c='red', alpha=0.7, marker='o', linewidths=0,\n",
    "                      label='spams')\n",
    "\n",
    "ax1.set_xlim(-2, 50)\n",
    "ax1.set_xticks(np.arange(5, 50, 5), minor=True)\n",
    "ax1.set_xlabel('Number of digits `chr_digits`')\n",
    "\n",
    "ax1.set_ylim(-0.5, 60)\n",
    "ax1.set_ylabel('Max word length `max_wd_len`', labelpad=7)\n",
    "\n",
    "ax1.grid(visible=True, which='major', linewidth=0.2)\n",
    "ax1.grid(visible=True, which='minor', linewidth=0.1)\n",
    "\n",
    "legend = ax1.legend()\n",
    "legend.legend_handles[0]._sizes = [30]\n",
    "legend.legend_handles[1]._sizes = [30]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b8c72",
   "metadata": {},
   "source": [
    "We show on figure 1 a scatter plot of the number of digits and max word length for both hams (blue) and spams (red). The surface of the points is proportional to the number of messages (with an offset of 2 to facilitate vizualization). Most hams have few digits and are made of short words. We expect that a simple linear model in our engineered feature space will perform very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1f029",
   "metadata": {},
   "source": [
    "## <a id=\"logreg\"></a> Benchmarking with a logistic regression\n",
    "\n",
    "We set up a simple logistic regression here as a benchmark for comparison with more advanced deep learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(cm: np.ndarray,\n",
    "                  print_cm: bool = True,\n",
    "                  print_precrec: bool = True)-> None:\n",
    "    \"\"\"\n",
    "    Print metrics related to the confusion matrix: precision, recall, F1-score.\n",
    "    \"\"\"\n",
    "    t = np.sum(cm, axis=1)[1]\n",
    "    recall = (cm[1, 1] / t) if t != 0 else 1.\n",
    "    t = np.sum(cm, axis=0)[1]\n",
    "    prec = (cm[1, 1] / t) if t != 0 else 1.\n",
    "    if print_cm:\n",
    "        print(\"Confusion matrix\\n\", cm / np.sum(cm))\n",
    "    if print_precrec:\n",
    "        print(f'Precision: {prec:.8}; recall: {recall:.8}')\n",
    "    print(f'F1-score: {2*prec*recall/(prec+recall):.8}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de3afd",
   "metadata": {},
   "source": [
    "### Model construction and training\n",
    "\n",
    "We keep things simple here: no parameter tuning or decision threshold adjustment. We split the dataset into a train and test set, the latter containing 20% of the observations. # We will retain this split for the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple train-test split, use the dataset with duplicates\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(\n",
    "    build_features(df['message']), df['is_spam'],\n",
    "    test_size=0.2, stratify=df['is_spam'], random_state=1234)\n",
    "\n",
    "## pipeline\n",
    "pipeline = Pipeline([('column_preprocessing', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "## training\n",
    "lr_model = pipeline.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830c38a",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e538b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = lr_model['column_preprocessing'].get_feature_names_out()\n",
    "coefs = lr_model['classifier'].coef_[0]\n",
    "for fn, c in zip(feature_names, coefs):\n",
    "    print(f'{fn:<10} : {c: .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7afbfa",
   "metadata": {},
   "source": [
    "The most determinant feature is clearly the number of digits in the message (spams have more), followed by the number of punctuation characters (spams have less). The other features are also good predictors, with the exception of the number of capitallized letters and their number at the beginning of the message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024af37",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "When considering the performance of our model, we must keep in mind that the masking of some spam words introduce biases. This is especially the case for the masking of digits, the most important feature for the classifiation. The evaluation below thus certainly overestimates the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===== Train set metrics =====')\n",
    "print_metrics(confusion_matrix(y_tr, lr_model.predict(X_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n===== Test set metrics =====')\n",
    "print_metrics(confusion_matrix(y_test, lr_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd04bfd",
   "metadata": {},
   "source": [
    "Not bad! We get a benchmark F1-score of about 0.9. Let us see if we can improve this score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcc2a5",
   "metadata": {},
   "source": [
    "## <a id=\"tfidf-mlp\"></a> A first model: Multi-layer perceptron and TF-IDF\n",
    "\n",
    "\n",
    "!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e6ac2",
   "metadata": {},
   "source": [
    "ChatGPT prompt:\n",
    "\n",
    "I need yout to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55458140-1bbf-4ff6-a3ce-d74c4a3dad1c",
   "metadata": {},
   "source": [
    "## <a id=\"perpectives\"></a>Perspectives\n",
    "\n",
    "Possible extensions with more data/more precise data.\n",
    "\n",
    "- Zipcode : do people prfer those who live closer\n",
    "- Sex orientation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root-me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
