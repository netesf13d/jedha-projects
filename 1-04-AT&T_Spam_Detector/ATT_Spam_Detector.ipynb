{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad6061b-8baa-4ab4-add0-db674cf11620",
   "metadata": {},
   "source": [
    "# **AT&T Spam Detector**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Contents\n",
    "--------\n",
    "1. [Data loading and preprocessing](#loading)\n",
    "2. [Preliminary data analysis](#eda)\n",
    "3. [Benchmarking with a logistic regression](#logreg)\n",
    "4. [A first neural network: Multi-layer perceptron and TF-IDF](#tfidf-mlp)\n",
    "4. [Gated Recurrent Units with character tokens](#gru-char)\n",
    "4. [Gated Recurrent Units with word tokens](#gru-word)\n",
    "4. [Gated Recurrent Units with word tokens](#attention-word)\n",
    "4. [Gated Recurrent Units with word tokens](#attention-token)\n",
    "4. [Conclusion and perspectives](#conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1811f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "rng = np.random.default_rng(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330265c",
   "metadata": {},
   "source": [
    "## <a id=\"loading\"></a> Data loading and preprocessing\n",
    "\n",
    "The dataset consists of 5574 entries, many of which have issues. Here is a non-exhaustive list:\n",
    "- The file doesn't decode as `UTF-8`. It must be decoded as `latin-1` or `mac-roman`.\n",
    "- Some rows are ill-formed (eg line 101 of the csv: `ham\"\"\",,,`)\n",
    "- Most rows have trailing commas\n",
    "- Some messages are anclosed in (possibly many) double quote characters\n",
    "- Single and double quotes are escaped with backslashes\n",
    "- Some spurious characters are present (eg `å` characters that systematically prepend pound symbols `£`)\n",
    "\n",
    "Fortunately, the original version of the dataset can be found [here](https://archive.ics.uci.edu/dataset/228/sms+spam+collection). Its entries are much cleaner than those of our dataset. We can use them as a comparison to setup the cleaning and processing for our dataset:\n",
    "- Strip the trailing commas\n",
    "- Completely remove the double quotes `\"`\n",
    "- Convert backslashes + single quote `\\'` into single quote `'`\n",
    "- Convert backslashes `\\` into double quotes `\"`\n",
    "- Remove the spurious characters `å`\n",
    "\n",
    "The implementation of this pipeline is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Loading and preprocessing the project dataset ##########\n",
    "with open('./spam.csv', 'rt', encoding='latin-1') as f:\n",
    "    f.readline() # remove header\n",
    "    raw_data = [row.strip().split(',', 1) for row in f.readlines()]\n",
    "\n",
    "## set target\n",
    "is_spam = np.array([True if row[0] == 'spam' else False for row in raw_data])\n",
    "\n",
    "## process and clean messages\n",
    "messages = [row[1].strip(',') \\\n",
    "                  .replace('\"', '') \\\n",
    "                  .replace(\"\\\\'\", \"'\") \\\n",
    "                  .replace('\\\\', '\"') \\\n",
    "                  .replace('å', '')\n",
    "            for row in raw_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1f96f",
   "metadata": {},
   "source": [
    "However, some encoding issues persist with some problematic characters still present in messages. To proceed with the project we will rather use this original dataset as the starting point. The messages still need some processing:\n",
    "- characters in HTML-escaped form are converted to the corresponding symbol\n",
    "- The `RIGHT SINGLE QUOTATION MARK` character (`\\x92`) is converted into a single quote `'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c04177",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Loading and preprocessing the original dataset ##########\n",
    "with open('../SMSSpamCollection', 'rt', encoding='utf-8') as f:\n",
    "    raw_data = [row.strip().split('\\t', 1) for row in f.readlines()]\n",
    "\n",
    "is_spam = np.array([True if row[0] == 'spam' else False for row in raw_data])\n",
    "messages = np.array([row[1].replace('&lt;', '<') \\\n",
    "                           .replace('&gt;', '>') \\\n",
    "                           .replace('&amp;', '&') \\\n",
    "                           .replace('\\x92', \"'\")\n",
    "     for row in raw_data], dtype=object)\n",
    "\n",
    "df = pd.DataFrame({'message': messages, 'is_spam': is_spam})\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb955c59",
   "metadata": {},
   "source": [
    "Our dataset contains a total of 5574 messages, with 4827 hams (86.6%) and 747 spams (13.4%). Some messages are duplicates. We choose not to remove them, they certainly represent frequent messages for which making a classification error should be penalized more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25683080",
   "metadata": {},
   "source": [
    "## <a id=\"eda\"></a> Preliminary data analysis\n",
    "\n",
    "The messages are quite complex, mixing  uppercase, lowercase, puctuation, alphanumeric and other exotic characters. Training a model to the data would certainly require some form of text normalization. However, this might cause a loss of information. In this section we try to somewhat keep this information and aggregate it in the form of a few descriptive to get insight about what makes a message a spam.\n",
    "\n",
    "An important remark is in order before proceeding with data analysis. Visual inspection of the dataset reveals the presence of some tokens specific to ham messages: `<#>`, `<DECIMAL>`, `<TIME>` and `<URL>` (they appear as `&lt;*&gt;` in the dataset). These were certainly introduced to mask personal information from hams. Although the kind of values that `<DECIMAL>`, `<TIME>` and `<URL>` replace is obvious, this is not the case for `<#>`, which seems to be used in replacement of any kind of value. The character `*` seems to also be used to replace personal information in some ham messages (see for instance message 983). However, this character is also present as such in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.DataFrame(\n",
    "    {'is_spam': df['is_spam'],\n",
    "     'count_<#>': df['message'].map(lambda x: x.count('<#>')),\n",
    "     'count_<DECIMAL>': df['message'].map(lambda x: x.count('<DECIMAL>')),\n",
    "     'count_<TIME>': df['message'].map(lambda x: x.count('<TIME>')),\n",
    "     'count_<URL>': df['message'].map(lambda x: x.count('<URL>')),\n",
    "     'count_*': df['message'].map(lambda x: x.count('*'))})\n",
    "\n",
    "tokens_df.groupby('is_spam').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8e2e9",
   "metadata": {},
   "source": [
    "Indeed, these tokens are specific to hams (except the character `*`). There presence, due to human annotations, could introduce important biases to an automated detection system if not handled properly.\n",
    "\n",
    "With this remark in mind, we can move to the characterization of messages using the following descriptive features:\n",
    "- `msg_len`, the length of the message;\n",
    "- `chr_caps`, the number of capitallized characters;\n",
    "- `chr_digit`, the number of digit characters in the message;\n",
    "- `chr_punct`, the number of punctuation characters in the message;\n",
    "- `max_wd_len`, he length of the longest character string (split by whitespaces);\n",
    "- `lex_money`, the number of some money-related words and characters: `'$'`, `'£'`, `'€'`, `'cash'`, `'free'`, `'price'` and `'prize'`. The presence of these tokens indicates that the message talks about money (after all, spamming is about getting money from people). We could also consider adding words related to the lexical field of sex.\n",
    "- `caps_first`, the number of consecutive capitallized characters at the beginning of the message.\n",
    "\n",
    "For the purpose of data visualization, we remove the duplicates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cebbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define some helper functions\n",
    "def count_tokens(msgs: pd.DataFrame, tokens: list['str'])-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in the token list from the casefolded messages.\n",
    "    \"\"\"\n",
    "    regex = '|'.join(tokens)\n",
    "    return msgs.apply(lambda x: len(re.findall(regex, x.casefold())))\n",
    "    \n",
    "\n",
    "def count_first_caps(s: str)-> int:\n",
    "    \"\"\"\n",
    "    Count the number of capitallized letters at the beginning of a string.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    for c in s:\n",
    "        if not c.isupper():\n",
    "            return n\n",
    "        n += 1\n",
    "    return n\n",
    "\n",
    "\n",
    "def build_features(msgs: pd.DataFrame)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract quantitative features from a series of messages.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'msg_len': msgs.apply(len),\n",
    "        'chr_caps': msgs.apply(lambda s: sum(c.isupper() for c in s)),\n",
    "        'chr_digit': msgs.apply(lambda s: sum(c.isdigit() for c in s)),\n",
    "        'chr_punct': msgs.apply(lambda s: sum(c in punctuation for c in s)),\n",
    "        'max_wd_len': msgs.apply(lambda s: max(len(x) for x in s.split(' '))),\n",
    "        'lex_money': count_tokens(msgs, [r'\\$', '£', '€', 'free', 'cash', 'price', 'prize']),\n",
    "        'caps_first': msgs.apply(count_first_caps)\n",
    "        }\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15563bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare dataset from extracted features\n",
    "df_ = df.drop_duplicates()\n",
    "X = build_features(df_['message'])\n",
    "y = df_['is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spam = X.loc[y]\n",
    "X_spam.describe().map(lambda x: f\"{x:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ham = X.loc[~y]\n",
    "X_ham.describe().map(lambda x: f\"{x:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c978ad",
   "metadata": {},
   "source": [
    "Some of our derived features are actually quite discriminating for the spam/ham nature of the messages.\n",
    "- The number of digits is clearly the most discriminating feature with a mean of 15 for spams vs 0.3 for hams. 75 % of spams have more than 10 digits while less than 25% have a single digit.\n",
    "- The presence of money-related words 'free', 'cash' and currency characters is also discriminative of spams, although many spams do not have any.\n",
    "- Spams tend to also have larger message lengths, capitallized characters and punctuation characters. However, there is more overlap between the two categories in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1, v2 = 'chr_digit', 'max_wd_len'\n",
    "\n",
    "## number of hams with given values of `v1` and `v2`\n",
    "count_ham = X_ham.loc[:, [v1, v2]].value_counts()\n",
    "x_ham, y_ham = count_ham.index.to_frame().to_numpy().T\n",
    "\n",
    "## number of spams with given values of `v1` and `v2`\n",
    "count_spam = X_spam.loc[:, [v1, v2]].value_counts()\n",
    "x_spam, y_spam = count_spam.index.to_frame().to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(5.5, 4.8), dpi=200,\n",
    "    gridspec_kw={'left': 0.12, 'right': 0.92, 'top': 0.9, 'bottom': 0.10}\n",
    ")\n",
    "fig1.suptitle('Figure 1: Scatter plot of messages characteristics',\n",
    "              x=0.02, ha='left')\n",
    "\n",
    "sc_ham = ax1.scatter(x_ham, y_ham, count_ham+2,\n",
    "                     c='blue', alpha=0.65, marker='o', linewidths=0,\n",
    "                     label='hams')\n",
    "sc_spam = ax1.scatter(x_spam, y_spam, count_spam+2,\n",
    "                      c='red', alpha=0.7, marker='o', linewidths=0,\n",
    "                      label='spams')\n",
    "\n",
    "ax1.set_xlim(-2, 50)\n",
    "ax1.set_xticks(np.arange(5, 50, 5), minor=True)\n",
    "ax1.set_xlabel('Number of digits `chr_digits`')\n",
    "\n",
    "ax1.set_ylim(-0.5, 60)\n",
    "ax1.set_ylabel('Max word length `max_wd_len`', labelpad=7)\n",
    "\n",
    "ax1.grid(visible=True, which='major', linewidth=0.2)\n",
    "ax1.grid(visible=True, which='minor', linewidth=0.1)\n",
    "\n",
    "legend = ax1.legend()\n",
    "legend.legend_handles[0]._sizes = [30]\n",
    "legend.legend_handles[1]._sizes = [30]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b8c72",
   "metadata": {},
   "source": [
    "We show on figure 1 a scatter plot of the number of digits and max word length for both hams (blue) and spams (red). The surface of the points is proportional to the number of messages (with an offset of 2 to facilitate vizualization). Most hams have few digits and are made of short words. We expect that a simple linear model in our engineered feature space will perform very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babfb8ac",
   "metadata": {},
   "source": [
    "## <a id=\"utils\"></a> Data preprocessing and utilities\n",
    "\n",
    "Before moving on to model construction and training, we first introduce here some utilities related to model evaluation. We also setup here the common parts of the training pipelines.\n",
    "\n",
    "\n",
    "### Preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6071346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_diacritics(txt: str)-> str:\n",
    "    \"\"\"\n",
    "    Remove all diacritics from words and characters forbidden in filenames.\n",
    "    \"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt\n",
    "                     if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7855033",
   "metadata": {},
   "source": [
    "### Model evaluation utilities\n",
    "\n",
    "We evaluate our classification models using metrics which are robust to the very high imbalance of fraud event occurences. These are derived from the confusion matrix:\n",
    "- The precision\n",
    "- The recall\n",
    "- The F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true: np.ndarray,\n",
    "                           y_pred: np.ndarray)-> None:\n",
    "    \"\"\"\n",
    "    Helper function to evaluate and return the relevant evaluation metrics:\n",
    "        confusion matrix, precision, recall, F1-score\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    t = np.sum(cm, axis=1)[1]\n",
    "    recall = (cm[1, 1] / t) if t != 0 else 1.\n",
    "    t = np.sum(cm, axis=0)[1]\n",
    "    prec = (cm[1, 1] / t) if t != 0 else 1.\n",
    "    f1 = 2*prec*recall/(prec+recall)\n",
    "    \n",
    "    return cm, prec, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe to hold the results\n",
    "metric_names = ['precision', 'recall', 'F1-score']\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [('Logistic regression', 'Random forest', 'hist gradient boosting'),\n",
    "     ('train', 'test')],\n",
    "    names=['model', 'eval. set'])\n",
    "evaluation_df = pd.DataFrame(\n",
    "    np.full((6, 3), np.nan), index=index, columns=metric_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1f029",
   "metadata": {},
   "source": [
    "## <a id=\"logreg\"></a> Benchmarking with a logistic regression\n",
    "\n",
    "We set up a simple logistic regression here as a benchmark for comparison with more advanced deep learning methods.\n",
    "\n",
    "\n",
    "### Model construction and training\n",
    "\n",
    "We keep things simple here: no parameter tuning or decision threshold adjustment. We split the dataset into a train and test set, the latter containing 20% of the observations. We will retain this split for the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple train-test split, use the dataset with duplicates\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(\n",
    "    build_features(df['message']), df['is_spam'],\n",
    "    test_size=0.2, stratify=df['is_spam'], random_state=1234)\n",
    "\n",
    "## pipeline\n",
    "pipeline = Pipeline([('column_preprocessing', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13dec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "t0 = time.time()\n",
    "lr_model = pipeline.fit(X_tr, y_tr)\n",
    "t1 = time.time()\n",
    "print(f'Logistic regression model training in {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830c38a",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e538b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = lr_model['column_preprocessing'].get_feature_names_out()\n",
    "coefs = lr_model['classifier'].coef_[0]\n",
    "for fn, c in zip(feature_names, coefs):\n",
    "    print(f'{fn:<10} : {c: .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7afbfa",
   "metadata": {},
   "source": [
    "The most determinant feature is clearly the number of digits in the message (spams have more), followed by the number of punctuation characters (spams have less). The other features are also good predictors, with the exception of the number of capitallized letters and their number at the beginning of the message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024af37",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "When considering the performance of our model, we must keep in mind that the masking of some spam words introduce biases. This is especially the case for the masking of digits, the most important feature for the classifiation. The evaluation below thus certainly overestimates the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate of train set\n",
    "y_pred_tr = lr_model.predict(X_tr)\n",
    "_, prec, recall, f1 = classification_metrics(y_tr, y_pred_tr)\n",
    "evaluation_df.iloc[0] = prec, recall, f1\n",
    "\n",
    "## evaluate on test set\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "_, prec, recall, f1 = classification_metrics(y_test, y_pred_test)\n",
    "evaluation_df.iloc[1] = prec, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66189604",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd04bfd",
   "metadata": {},
   "source": [
    "Not bad! We get a benchmark F1-score of about 0.9. Let us see if we can improve this score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcc2a5",
   "metadata": {},
   "source": [
    "## <a id=\"tfidf-mlp\"></a> A first neural network: Multi-layer perceptron and TF-IDF\n",
    "\n",
    "\n",
    "\n",
    "### Text preprocessing\n",
    "\n",
    "The text prepocessing proceeds in 4 steps:\n",
    "1. Remove diacritics and casefold the messages.\n",
    "2. Lemmatize words. However, we keep stop words as valid tokens.\n",
    "3. Replace tokens containing digits with a special token `'<num>'`. This includes the tokens `<DECIMAL>` and `<TIME>` from hams.\n",
    "Also discard the ham-specific token `<#>`.\n",
    "4. Finally, replace tokens with a single occurrence (including the ham-specific token `<URL>`) with an out-of-vocabulary token (`<oov>`).\n",
    "This processing is currently not available with scikit-learn `CountVectorizer`, so we do it manually.\n",
    "\n",
    "Most of the messages are written in [SMS language](https://en.wikipedia.org/wiki/SMS_language) with inconsistent style.\n",
    "Our tokenization will produce different tokens for words that have essentially the same meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc449049",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1: remove diacritics and preprocess\n",
    "norm_msgs = df['message'].apply(strip_diacritics).apply(str.casefold)\n",
    "norm_msgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 2: lemmatize words, remove punctuation\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "corpus = []\n",
    "for msg in norm_msgs:\n",
    "    doc = nlp(msg)\n",
    "    doc = ' '.join(wd.lemma_ for wd in doc if not wd.is_punct)\n",
    "                   # if wd.is_alpha and not wd.is_stop)\n",
    "    corpus.append(doc)\n",
    "corpus = np.array(corpus, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 3: replace numbers and specific tokens\n",
    "preprocessed_corpus = np.empty_like(corpus, dtype=object)\n",
    "for i, msg in enumerate(corpus):\n",
    "    msg = msg.replace(' < > ', '') # discard `< # >` token\n",
    "    msg = re.sub(r'< decimal >|< time >', '<num>', msg) # replace number masking tokens with `<num>`\n",
    "    msg = re.sub(r'\\b[,\\.\\-\\w]*\\d[,\\.\\-\\w]*\\b', '<num>', msg) # replace numbers with `<num>`\n",
    "    msg = re.sub(r'\\s+', ' ', msg) # replace consecutive whitespaces with single whitespace\n",
    "    preprocessed_corpus[i] = msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[12])\n",
    "print('----------')\n",
    "print(preprocessed_corpus[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b959c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[802])\n",
    "print('----------')\n",
    "print(preprocessed_corpus[802])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[2408])\n",
    "print('----------')\n",
    "print(preprocessed_corpus[2408])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: manual handling of singwords\n",
    "text = ' ## '.join(preprocessed_corpus)\n",
    "\n",
    "vocab, counts = np.unique(text.split(' '), return_counts=True)\n",
    "single_words = vocab[counts == 1]\n",
    "for wd in single_words:\n",
    "    text = text.replace(f' {wd} ', ' <oov> ')\n",
    "processed_corpus = np.array(text.split(' ## '), dtype=np.str_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f369a",
   "metadata": {},
   "source": [
    "### Model construction and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e40828",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the TF-IDF matrix\n",
    "vectorizer = CountVectorizer(token_pattern=r'[^\\s]+')\n",
    "word_counts = vectorizer.fit_transform(processed_corpus)\n",
    "tfidf = TfidfTransformer(norm='l2').fit_transform(word_counts)\n",
    "tfidf\n",
    "\n",
    "## Train-test split\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(\n",
    "    tfidf, df['is_spam'], test_size=0.2, stratify=df['is_spam'],\n",
    "    random_state=SEED)\n",
    "\n",
    "## MLP classifer, no preprocessing pipeline\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(1000, 300, 100, 10),\n",
    "                          solver='adam', alpha=1e-1,\n",
    "                          max_iter=300, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "mlp_model.fit(X_tr, y_tr)\n",
    "t1 = time.time()\n",
    "print(f'Multi-layer perceptron training in {t1-t0:.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e6ac2",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate of train set\n",
    "y_pred_tr = mlp_model.predict(X_tr)\n",
    "_, prec, recall, f1 = classification_metrics(y_tr, y_pred_tr)\n",
    "evaluation_df.iloc[1] = prec, recall, f1\n",
    "\n",
    "## evaluate on test set\n",
    "y_pred_test = mlp_model.predict(X_test)\n",
    "_, prec, recall, f1 = classification_metrics(y_test, y_pred_test)\n",
    "evaluation_df.iloc[3] = prec, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80735612",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0daeb",
   "metadata": {},
   "source": [
    "The F1-score reaches a value of 93.1% on the test set, a significative improvement over the simple linear regression. However, this comes at the cost of a much longer training time. Another drawback is the tendency of the model to overfit, as indicated by the difference between train and test F1-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c519f",
   "metadata": {},
   "source": [
    "## <a id=\"gru-char\"></a> Gated Recurrent Units with character tokens\n",
    "\n",
    "The messages are rather short, we can therefore consider a tokenization at the character level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d730863",
   "metadata": {},
   "source": [
    "## <a id=\"gru-token\"></a> Gated Recurrent Units with word tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1c888",
   "metadata": {},
   "source": [
    "## <a id=\"attention-word\"></a> Gated Recurrent Units with word tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d9afb3",
   "metadata": {},
   "source": [
    "## <a id=\"attention-token\"></a> Gated Recurrent Units with word tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55458140-1bbf-4ff6-a3ce-d74c4a3dad1c",
   "metadata": {},
   "source": [
    "## <a id=\"perpectives\"></a>Perspectives\n",
    "\n",
    "Possible extensions with more data/more precise data.\n",
    "\n",
    "- Zipcode : do people prfer those who live closer\n",
    "- Sex orientation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root-me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
