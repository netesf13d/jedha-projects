# jedha-projects

Collection of Jedha projects for certification.

This repository contains the various projects required for the validation of:
- The certification "Concepteur developpeur en science des donnees" (RNCP35288)
- The certification "Architecte en Intelligence Artificielle" (RNCP38777)

The projects are divided into 8 blocks. Blocks 1 - 5 are required for the CDSD certification, and blocks 6-8 are required for the AIA certificate.

In addition, the two certifications require a "final project" for validation. The same project was adapted to both certifications and is available [here](https://github.com/netesf13d/crypto-crash-detection).


## Block 1-01 - Building and Managing a Data Infrastructure

- Design a robust data architecture with Data Lakes and Warehouses to meet storage, security, and usage needs.
- Implement distributed storage and computing using tools like Spark or AWS Redshift for Big Data management.
- Collect data from various sources (Web, internal, external) using tools like Scrapy while ensuring GDPR compliance.
- Clean and structure data with ETL processes to make it accessible and understandable for business teams.

- Implement a data architecture with data lakes and data warehouses.
- Integrate distributed storage and computation to the architecture
- Collect data from various sources using APIs or web scraping
- Process the data and load it in the database


### Plan your trip with Kayak

Construction of a database.


## Block 1-02 - Exploratory Data Analysis

- Process databases with descriptive and inferential statistics using Numpy or Pandas to clean and normalize data.
- Conduct univariate and multivariate analyses to identify relationships between variables in structured datasets.
- Enhance statistical analysis with parallel processing using tools like Spark for faster Big Data computation.
- Visualize statistical results effectively with Plotly or Matplotlib to support decision-making for non-experts.


### Speed Dating

The exploratory data analysis of data gathered from surveys during a speed dating exeriment.


### Steam videogames platform

Analyze videogames consumption.



## Block 1-03 - Predictive Analysis of Structured Data

- Process structured data with ML pipelines using Scikit-Learn to encode, normalize, and prepare data for analysis.
- Perform predictive analysis with supervised learning to automate tasks based on algorithmic predictions.
- Develop unsupervised learning algorithms for data segmentation or dimensionality reduction to enhance insights.
- Evaluate and improve ML model performance by analyzing variable influence to demonstrate business value.


### Conversion rate challenge

Participate to an artificial machine learning challenge.


### Walmart Sales

An application of supervised machine learning to the prediction of weekly sales of Walmart stores.


### The North Face e-commerce

Use product descriptions to categorize them and make recommendations.


## Block 1-04 - Predictive Analysis of Unstructured Data

- Process unstructured data (images, text, audio) with TensorFlow or Numpy to convert them into machine-readable matrices.
- Build neural networks (classic, CNNs, RNNs) using TensorFlow to analyze unstructured data and detect patterns.
- Develop accurate deep learning models by fine-tuning pre-trained neural networks for large-scale predictions.
- Generate synthetic unstructured data using adversarial networks to create new training datasets for AI applications.
- Evaluate deep learning models with training and validation metrics to prepare for industrial deployment.


### AT&T Spam Detector

Classify SMS texts into spams or hams with NLP.


## Block 1-05 - Deployment and Automatization

- Standardize ML model deployment with tools like MLflow and Docker for seamless AI project integration.
- Develop an API using AWS SageMaker to scale ML predictions across business teams.
- Deploy web applications integrating predictive analytics (ML & Deep Learning) with Flask, Heroku, or AWS SageMaker for decision automation.


### Getaround Analysis

Optimize the pricing and deploy a dashboard for a car rental service.


## Block 1-06 - Management of a Data Project

- Translate business needs into data challenges to align AI solutions with organizational goals.
- Stay up-to-date with the latest technologies through continuous learning to provide the best data solutions.
- Define project scope, timeline, and budget to present and justify data initiatives to business stakeholders.
- Manage data projects (Statistics, ML, Deep Learning, Big Data) using KPIs and dashboards while ensuring GDPR compliance.
- Communicate insights effectively to help business teams implement data-driven strategies.
- Lead data projects from inception to deployment, ensuring coordination across teams and continuous project oversight.


## Block 2-01 - Data Governance and Strategy

- Create a Data Governance policy with stakeholders to ensure compliance, data quality, security, and confidentiality.
- Collaborate with teams to implement and promote Data Governance across company practices.
- Train and raise awareness on Data Governance principles for an inclusive and effective implementation.
- Conduct regular audits to ensure compliance with local and international data management regulations.
- Assess data management risks to strengthen governance policies around quality and security.


### Spotify Data Governance

Design and pilot a Data Governance framework for Spotify.


## Block 2-02 - AI Data Architecture Design and Deployment

- Identify architectural needs by analyzing technical, operational, and regulatory constraints.
- Develop a data architecture specification aligned with company requirements.
- Create logical and physical data models (e.g., entity-relationship, star schema) based on specifications.
- Design optimized database structures considering performance, security, scalability, and data volume.
- Deploy virtual servers (cloud or on-premise) to support AI algorithm training with large datasets.
- Boost computing power with server clusters for AI training, big data storage, and heavy traffic handling.
- Set up monitoring tools to proactively track and optimize data infrastructure performance.
- Document architecture specifications clearly and accessibly for seamless management.


### Automatic Fraud Detection




## Block 2-03 - Data Pipelines for AI

- Build a real-time data management system tailored to the companyâ€™s operational constraints.
- Create ETL/ELT pipelines for seamless data transfer and transformation across databases.
- Automate data flows to optimize infrastructure performance.
- Monitor data streams to ensure quality, security, and governance compliance.
- Develop quality control and error correction procedures to maintain high data integrity.


### Stripe Business Case

In this project, we propose a complete data infrastructure for Stripe, an online payment solutions company.


## Block 2-04 - Creation and Deployment of a AI solution

- Draft an AI solution specification to meet technical and economic needs, ensuring accessibility.
- Develop an AI algorithm tailored to training data and project requirements.
- Adapt infrastructure with APIs to support AI production deployment.
- Design CI/CD pipelines to automate AI solution deployment.
- Create model retraining scripts to maintain and optimize Machine Learning processes.
- Monitor AI performance with tools like Aporia or Evidently to ensure production reliability and compliance.

