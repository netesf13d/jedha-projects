{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16166ceb",
   "metadata": {},
   "source": [
    "# Data Collection and Storage\n",
    "\n",
    "This notebook illustrates the collection and storage of data used for the project application.\n",
    "\n",
    "Contents\n",
    "--------\n",
    "1. [Fetching data through API calls](#api)\n",
    "    1. [Get geocoding information](#geocoding)\n",
    "    2. [Get weather forecast](#weather)\n",
    "2. [Web scraping](#scraping)\n",
    "    1. [Reverse engineering the website requests](#scraping_reverse)\n",
    "    2. [Get hotel information by scraping](#scraping_fetch)\n",
    "3. [Storage in a data lake](#datalake)\n",
    "4. [Storage in a database](#database)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f2e91",
   "metadata": {},
   "source": [
    "## <a id=\"api\"></a>API Calls\n",
    "\n",
    "We request APIs to get geocoding information from the name of a place and weather forecast at given geographic coordinates. Utilities for the corresponding API calls are defined in the module `etl/api_mgmt.py`. To use them, we first setup a `requests.Session`. Since the API servers may limit the number of allowed requests, we add a retry policy to the HTTP session. We also load a file containing the names of the locations of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5df9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "from etl import get_coords, get_weather_forecast, save_to_json\n",
    "\n",
    "BUCKET_NAME = './bucket_name.key'\n",
    "S3_WRITER_ACCESS_KEYS = './certification-project-s3-writer_accessKeys.key'\n",
    "S3_READER_ACCESS_KEYS = './certification-project-s3-reader_accessKeys.key'\n",
    "DB_ACCESS_KEYS = './db_access_keys.key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b12a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup session with retry policy in case of failure\n",
    "s = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[403, 502, 503, 504])\n",
    "s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "# Load locations of interest\n",
    "with open(\"./data/places.csv\", 'rt', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader, None) # remove header\n",
    "    locations = [row for row in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9549f80",
   "metadata": {},
   "source": [
    "### <a id=\"geocoding\"></a>Get geocoding information\n",
    "\n",
    "We use [Nominatim API](https://nominatim.org/) to fetch geocoding information. The API is quite restrictive in its [use policy](https://operations.osmfoundation.org/policies/nominatim/). Most importantly, the number of requests is limited to one per second, which forces us to throttle the rate accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2862d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Rouen',\n",
       " 'country': 'France',\n",
       " 'latitude': 49.4404591,\n",
       " 'longitude': 1.0939658}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = {}\n",
    "for i, loc in enumerate(locations, start=1):\n",
    "    coordinates[i] = ({'name': loc[0], 'country': loc[1]} \n",
    "                      | get_coords(s, f\"{loc[0]}, {loc[1]}\"))\n",
    "    time.sleep(1.1)\n",
    "\n",
    "coordinates[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ad7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "locations_cols = ['location_id', 'name', 'country', 'latitude', 'longitude']\n",
    "with open('./data/locations.csv', 'wt', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=';', quoting=csv.QUOTE_STRINGS)\n",
    "    writer.writerow(locations_cols)\n",
    "    for i, coords in coordinates.items():\n",
    "        writer.writerow([i] + [coords[col] for col in locations_cols[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4a818",
   "metadata": {},
   "source": [
    "### <a id=\"weather\"></a>Get weather forecast\n",
    "\n",
    "We use [Open-Meteo API](https://open-meteo.com/en/docs) to get weather forecast information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f47b8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 49.44,\n",
       " 'longitude': 1.0999999,\n",
       " 'generationtime_ms': 0.20241737365722656,\n",
       " 'utc_offset_seconds': 3600,\n",
       " 'timezone': 'Europe/Paris',\n",
       " 'timezone_abbreviation': 'GMT+1',\n",
       " 'elevation': 24.0,\n",
       " 'daily_units': {'time': 'iso8601',\n",
       "  'temperature_2m_max': '°C',\n",
       "  'temperature_2m_min': '°C',\n",
       "  'sunshine_duration': 's',\n",
       "  'precipitation_sum': 'mm'},\n",
       " 'daily': {'time': ['2025-02-24',\n",
       "   '2025-02-25',\n",
       "   '2025-02-26',\n",
       "   '2025-02-27',\n",
       "   '2025-02-28',\n",
       "   '2025-03-01',\n",
       "   '2025-03-02',\n",
       "   '2025-03-03',\n",
       "   '2025-03-04',\n",
       "   '2025-03-05',\n",
       "   '2025-03-06',\n",
       "   '2025-03-07',\n",
       "   '2025-03-08',\n",
       "   '2025-03-09',\n",
       "   '2025-03-10',\n",
       "   '2025-03-11'],\n",
       "  'temperature_2m_max': [13.6,\n",
       "   9.4,\n",
       "   10.2,\n",
       "   9.1,\n",
       "   9.7,\n",
       "   8.8,\n",
       "   9.9,\n",
       "   9.8,\n",
       "   12.3,\n",
       "   17.2,\n",
       "   15.8,\n",
       "   17.6,\n",
       "   12.2,\n",
       "   9.6,\n",
       "   11.2,\n",
       "   9.1],\n",
       "  'temperature_2m_min': [9.7,\n",
       "   5.9,\n",
       "   4.9,\n",
       "   3.5,\n",
       "   1.2,\n",
       "   0.6,\n",
       "   0.2,\n",
       "   0.9,\n",
       "   2.4,\n",
       "   6.8,\n",
       "   7.1,\n",
       "   7.3,\n",
       "   7.0,\n",
       "   5.4,\n",
       "   5.3,\n",
       "   2.7],\n",
       "  'sunshine_duration': [10052.75,\n",
       "   0.0,\n",
       "   3475.58,\n",
       "   35000.45,\n",
       "   29757.01,\n",
       "   35822.32,\n",
       "   35846.06,\n",
       "   24640.98,\n",
       "   32223.22,\n",
       "   36786.82,\n",
       "   36983.39,\n",
       "   37208.34,\n",
       "   25876.54,\n",
       "   33300.95,\n",
       "   37392.86,\n",
       "   30876.76],\n",
       "  'precipitation_sum': [5.3,\n",
       "   3.2,\n",
       "   12.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.5,\n",
       "   1.2,\n",
       "   1.5,\n",
       "   0.6]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_forecast = {}\n",
    "for i, coords in coordinates.items():\n",
    "    weather_forecast[i] = get_weather_forecast(\n",
    "        s, coords['latitude'], coords['longitude'])\n",
    "\n",
    "weather_forecast[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361feca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "# take the average weather over the next 7 days\n",
    "weather_cols = [\n",
    "    'location_id', 'date', 'min_temperature_cels', 'max_temperature_cels',\n",
    "    'sunshine_duration_h', 'precipitation_sum_mm'\n",
    "]\n",
    "with open('./data/weather_indicators.csv', 'wt', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=';', quoting=csv.QUOTE_STRINGS)\n",
    "    writer.writerow(weather_cols)\n",
    "    for i, forecast in weather_forecast.items():\n",
    "        forecast = forecast['daily']\n",
    "        row = [i, forecast['time'][0],\n",
    "               np.mean(forecast['temperature_2m_min'][:8]),\n",
    "               np.mean(forecast['temperature_2m_max'][:8]),\n",
    "               np.mean(forecast['sunshine_duration'][:8])/3600,\n",
    "               np.mean(forecast['precipitation_sum'][:8])]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38442342",
   "metadata": {},
   "source": [
    "## <a id=\"scraping\"></a>Web scraping\n",
    "\n",
    "The collection of hotels information at the selected locations is done through web scraping of [booking.com](https://www.booking.com). This approach is more complex and unstable than API calls. It is standard practice to first study how requests and responses are related to web browser interaction. This will allow us to tailor automated requests for scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d311c1",
   "metadata": {},
   "source": [
    "### <a id=\"scraping_reverse\"></a>Reverse engineering the website requests\n",
    "\n",
    "The first step is to get the request resulting from regular user interaction. We thus go to the index page [https://www.booking.com/index.en-gb.html](https://www.booking.com/index.en-gb.html) and fill the search bar. Here we look for an hotal in Rouen, France for 2 adults between march, 1st and march, 9th.\n",
    "\n",
    "<img src=\"media/booking_search.png\" alt=\"booking_search\" width=\"1000\"/>\n",
    "\n",
    "After clicking on \"Search\" the request actually sent by the web browser is displayed in the address bar. This allows us to recover the parameters of the GET request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ab4a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ss=Rouen%2C+France',\n",
       " 'efdco=1',\n",
       " 'label=gen173nr-1FCAEoggI46AdICVgEaE2IAQGYAQm4ARjIAQ_YAQHoAQH4AQKIAgGoAgS4AsWf4r0GwAIB0gIkYmMwNmI1MjktMzkyZS00N2FjLTllNWYtOWZmZGIwMWZjODhj2AIF4AIB',\n",
       " 'aid=304142',\n",
       " 'lang=en-gb',\n",
       " 'sb=1',\n",
       " 'src_elem=sb',\n",
       " 'src=index',\n",
       " 'dest_id=-1462807',\n",
       " 'dest_type=city',\n",
       " 'ac_position=0',\n",
       " 'ac_click_type=b',\n",
       " 'ac_langcode=en',\n",
       " 'ac_suggestion_list_length=5',\n",
       " 'search_selected=true',\n",
       " 'search_pageview_id=a6f166e2b250077a',\n",
       " 'ac_meta=GhBhNmYxNjZlMmIyNTAwNzdhIAAoATICZW46DVJvdWVuLCBGcmFuY2VAAEoAUAA%3D',\n",
       " 'checkin=2025-03-01',\n",
       " 'checkout=2025-03-09',\n",
       " 'group_adults=2',\n",
       " 'no_rooms=1',\n",
       " 'group_children=0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_url = 'https://www.booking.com/searchresults.en-gb.html?ss=Rouen%2C+France&efdco=1&label=gen173nr-1FCAEoggI46AdICVgEaE2IAQGYAQm4ARjIAQ_YAQHoAQH4AQKIAgGoAgS4AsWf4r0GwAIB0gIkYmMwNmI1MjktMzkyZS00N2FjLTllNWYtOWZmZGIwMWZjODhj2AIF4AIB&aid=304142&lang=en-gb&sb=1&src_elem=sb&src=index&dest_id=-1462807&dest_type=city&ac_position=0&ac_click_type=b&ac_langcode=en&ac_suggestion_list_length=5&search_selected=true&search_pageview_id=a6f166e2b250077a&ac_meta=GhBhNmYxNjZlMmIyNTAwNzdhIAAoATICZW46DVJvdWVuLCBGcmFuY2VAAEoAUAA%3D&checkin=2025-03-01&checkout=2025-03-09&group_adults=2&no_rooms=1&group_children=0'\n",
    "\n",
    "req_url.split('?')[1].split('&')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c216cd85",
   "metadata": {},
   "source": [
    "We can already get a few insights from the request URL:\n",
    "- `ss` (search string) corresponds to the text written in the search bar,\n",
    "- `checkin` and `checkout` correspond to the travel dates (the calendar widget in the center),\n",
    "- `group_adults`, `no_rooms` and `group_children` correspond to the input of the right widget.\n",
    "\n",
    "It turns out that a valid request can be made with a different approach, by specifying only the latitude and longitude of the destination. For instance, the URL\n",
    "`'https://www.booking.com/searchresults.en-gb.html?latitude=49.4404591&longitude=1.0939658'` yields a page with the hotels ranked by inreasing distance to the coordinates. The parameters above can also be specified to refine the search, but we will not use them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07a710",
   "metadata": {},
   "source": [
    "### <a id=\"scraping_fetch\"></a>Get hotel information by scraping\n",
    "\n",
    "The above analysis helped to setup the scraping functionality, which is implemented in the module `etl/scraping_mgmt.py`. Let us detail briefly the sraping procedure:\n",
    "- We reach the target website through an automated browser driven with  [Selenium](https://www.selenium.dev/) WebDriver. We favor this approach over other possibilities such as using `scrapy`. The reason is that the page loading of our target, booking.com, is mostly done through scrolling. This feature is implemented in javascript and is complex to trigger if the scraping tool used cannot execute javascript. A browser, however, natively executes javascript and therefore suits better our task.\n",
    "- For each location, we send a request with the URL `'https://www.booking.com/searchresults.en-gb.html?latitude={latitude}&longitude={longitude}'`.\n",
    "- We scrape the hotels data that we need, scrolling down if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ace075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from etl import scrape_from_searchpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup driver with options to prevent detection\n",
    "## See https://stackoverflow.com/questions/53039551/selenium-webdriver-modifying-navigator-webdriver-flag-to-prevent-selenium-detec/53040904#53040904\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "driver.execute_cdp_cmd(\n",
    "    'Network.setUserAgentOverride',\n",
    "    {\"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.53 Safari/537.36'}\n",
    ")\n",
    "driver.implicitly_wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1d0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/locations.csv\", 'rt', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=';', quoting=csv.QUOTE_STRINGS)\n",
    "    next(reader, None) # remove header\n",
    "    locations = [row for row in reader]\n",
    "\n",
    "search_urls = {int(loc[0]): ('https://www.booking.com/searchresults.en-gb.html?'\n",
    "                            f'latitude={loc[3]}&longitude={loc[4]}')\n",
    "               for loc in locations}\n",
    "\n",
    "for i, search_url in search_urls.items():\n",
    "    hotel_infos = {i: scrape_from_searchpage(driver, search_url, limit=30)} # scrape on search\n",
    "    save_to_json(f'./data/temp/{i}.json', hotel_infos)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79bde280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load temporary saved files\n",
    "hotels_list = []\n",
    "root, _, files = next(os.walk('./data/temp/'))\n",
    "for file in files:\n",
    "    with open(root + file, 'rt', encoding='utf-8') as f:\n",
    "        hotels_list.append(json.load(f))\n",
    "\n",
    "# transform and save csv\n",
    "hotels_cols = ['hotel_id', 'location_id', 'url', 'name',\n",
    "               'description', 'rating', 'georating']\n",
    "hotel_id = 1\n",
    "hotels_data = []\n",
    "for hotels in hotels_list:\n",
    "    loc_id, hotels = next(iter(hotels.items()))\n",
    "    for h in hotels:\n",
    "        entry = [hotel_id, int(loc_id)] + [h[col] for col in hotels_cols[2:]]\n",
    "        hotels_data.append(entry)\n",
    "        hotel_id += 1\n",
    "\n",
    "with open('./data/hotels.csv', 'wt', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=';', quoting=csv.QUOTE_STRINGS)\n",
    "    writer.writerow(hotels_cols)\n",
    "    for row in hotels_data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d2955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove temp directory\n",
    "shutil.rmtree('./data/temp/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec1e75",
   "metadata": {},
   "source": [
    "## <a id=\"datalake\"></a>Storage in a data lake\n",
    "\n",
    "For long-term storage, the collected data is transferred a data lake in csv format. We use an AWS S3 bucket for that purpose. The interaction with an S3 bucket through `boto3` is simple enough so that no wrappers need to be implemented for uploading. The module `etl/s3_mgmt.py` implements only a function for downloading and formatting the csv into a structure suitable for transfer to the database. The data is stored as multiple csv files matching the database structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b7a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dde37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create S3 client with writing permission\n",
    "with open(BUCKET_NAME, 'rt', encoding='utf-8') as f:\n",
    "    bucket_name = f.read()\n",
    "with open(S3_WRITER_ACCESS_KEYS, 'rt', encoding='utf-8') as f:\n",
    "    aws_access_key_id, aws_secret_access_key = f.readlines()[-1].strip().split(',')\n",
    "\n",
    "s3_writer = boto3.client('s3', # region_name=region_name,\n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f73e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uplpoad the files created\n",
    "s3_writer.upload_file('./data/locations.csv', Bucket=bucket_name, Key='data/locations.csv')\n",
    "s3_writer.upload_file('./data/weather_indicators.csv', Bucket=bucket_name, Key='data/weather_indicators.csv')\n",
    "s3_writer.upload_file('./data/hotels.csv', Bucket=bucket_name, Key='data/hotels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fa0f9",
   "metadata": {},
   "source": [
    "The uploaded data can be inspected directly from the AWS web interface, as shown in the screenshot below.\n",
    "\n",
    "<img src=\"media/S3_storage.png\" alt=\"AWS S3 storage\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55f594",
   "metadata": {},
   "source": [
    "## <a id=\"database\"></a>Storage in a database\n",
    "\n",
    "We use a database to load data for the application. The functionality to transfer and load data from the database is implemented in the module `etl/db_mgmt.py`. We use SQLAlchemy to define our database structure, connected to a PostgreSQL database hosted on [Neon](https://neon.tech). The structure of the database is the following.\n",
    "\n",
    "<img src=\"media/DB_structure.png\" alt=\"Database structure\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72ac35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, URL, inspect\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from etl import download_csv\n",
    "from etl import Base, Location, Hotel, WeatherIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd875bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get credentials\n",
    "with open(DB_ACCESS_KEYS, 'rt', encoding='utf-8') as f:\n",
    "    pghost = f.readline().split(\"'\")[1]\n",
    "    pgdatabase = f.readline().split(\"'\")[1]\n",
    "    pguser = f.readline().split(\"'\")[1]\n",
    "    pgpassword = f.readline().split(\"'\")[1]\n",
    "\n",
    "url = URL.create(\n",
    "    \"postgresql+psycopg\",\n",
    "    username=pguser,\n",
    "    password=pgpassword,\n",
    "    host=pghost,\n",
    "    database=pgdatabase,\n",
    ")\n",
    "\n",
    "## setup SQL engine\n",
    "engine = create_engine(url, echo=False)\n",
    "# inspector = inspect(engine)\n",
    "\n",
    "## clear the database\n",
    "# Base.metadata.drop_all(engine)\n",
    "\n",
    "## create the database\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0331f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create S3 client with only readig permission\n",
    "with open(S3_READER_ACCESS_KEYS, 'rt', encoding='utf-8') as f:\n",
    "    aws_access_key_id, aws_secret_access_key = f.readlines()[-1].strip().split(',')\n",
    "\n",
    "s3_reader = boto3.client('s3', # region_name=region_name,\n",
    "                         aws_access_key_id=aws_access_key_id, \n",
    "                         aws_secret_access_key=aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3245dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from S3 buckets\n",
    "locations = download_csv(s3_reader, bucket_name, 'data/locations.csv')\n",
    "locations = [Location(**d) for d in locations]\n",
    "\n",
    "weather_indicators = download_csv(s3_reader, bucket_name, 'data/weather_indicators.csv')\n",
    "weather_indicators = [WeatherIndicator(**d) for d in weather_indicators]\n",
    "\n",
    "hotels = download_csv(s3_reader, bucket_name, 'data/hotels.csv')\n",
    "hotels = [Hotel(**d) for d in hotels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "345fda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transfer to database\n",
    "Base.metadata.create_all(engine)\n",
    "with Session(engine) as session:\n",
    "    session.add_all(locations)\n",
    "    session.commit()\n",
    "    session.add_all(weather_indicators)\n",
    "    session.commit()\n",
    "    session.add_all(hotels)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39badd66",
   "metadata": {},
   "source": [
    "The transferred data can be seen on the server, as shown below.\n",
    "\n",
    "<img src=\"media/DB_storage.png\" alt=\"Database structure\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28fb98",
   "metadata": {},
   "source": [
    "Finally, we can load the database contents directly into a pandas `DataFrame`, which is how we will load the data to display in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a11b6b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mont Saint Michel</td>\n",
       "      <td>France</td>\n",
       "      <td>48.635954</td>\n",
       "      <td>-1.511460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>St Malo</td>\n",
       "      <td>France</td>\n",
       "      <td>48.649518</td>\n",
       "      <td>-2.026041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bayeux</td>\n",
       "      <td>France</td>\n",
       "      <td>49.276462</td>\n",
       "      <td>-0.702474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Le Havre</td>\n",
       "      <td>France</td>\n",
       "      <td>49.493898</td>\n",
       "      <td>0.107973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>France</td>\n",
       "      <td>49.440459</td>\n",
       "      <td>1.093966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>48.858890</td>\n",
       "      <td>2.320041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Amiens</td>\n",
       "      <td>France</td>\n",
       "      <td>49.894171</td>\n",
       "      <td>2.295695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Lille</td>\n",
       "      <td>France</td>\n",
       "      <td>50.636565</td>\n",
       "      <td>3.063528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>France</td>\n",
       "      <td>48.584614</td>\n",
       "      <td>7.750713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chateau du Haut Koenigsbourg</td>\n",
       "      <td>France</td>\n",
       "      <td>48.249411</td>\n",
       "      <td>7.344320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Colmar</td>\n",
       "      <td>France</td>\n",
       "      <td>48.077752</td>\n",
       "      <td>7.357964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Eguisheim</td>\n",
       "      <td>France</td>\n",
       "      <td>48.044797</td>\n",
       "      <td>7.307962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Besancon</td>\n",
       "      <td>France</td>\n",
       "      <td>47.238022</td>\n",
       "      <td>6.024362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Dijon</td>\n",
       "      <td>France</td>\n",
       "      <td>47.321581</td>\n",
       "      <td>5.041470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>France</td>\n",
       "      <td>45.899235</td>\n",
       "      <td>6.128885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>France</td>\n",
       "      <td>45.187560</td>\n",
       "      <td>5.735782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>France</td>\n",
       "      <td>45.757814</td>\n",
       "      <td>4.832011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Gorges du Verdon</td>\n",
       "      <td>France</td>\n",
       "      <td>43.749656</td>\n",
       "      <td>6.328562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Bormes les Mimosas</td>\n",
       "      <td>France</td>\n",
       "      <td>43.150697</td>\n",
       "      <td>6.341928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Cassis</td>\n",
       "      <td>France</td>\n",
       "      <td>43.214036</td>\n",
       "      <td>5.539632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>France</td>\n",
       "      <td>43.296174</td>\n",
       "      <td>5.369953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Aix en Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>43.529842</td>\n",
       "      <td>5.447474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Avignon</td>\n",
       "      <td>France</td>\n",
       "      <td>43.949249</td>\n",
       "      <td>4.805901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Uzes</td>\n",
       "      <td>France</td>\n",
       "      <td>44.012128</td>\n",
       "      <td>4.419672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Nimes</td>\n",
       "      <td>France</td>\n",
       "      <td>43.837425</td>\n",
       "      <td>4.360069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Aigues Mortes</td>\n",
       "      <td>France</td>\n",
       "      <td>43.566152</td>\n",
       "      <td>4.191540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Saintes Maries de la mer</td>\n",
       "      <td>France</td>\n",
       "      <td>43.451592</td>\n",
       "      <td>4.427720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Collioure</td>\n",
       "      <td>France</td>\n",
       "      <td>42.525050</td>\n",
       "      <td>3.083155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Carcassonne</td>\n",
       "      <td>France</td>\n",
       "      <td>43.213036</td>\n",
       "      <td>2.349107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Ariege</td>\n",
       "      <td>France</td>\n",
       "      <td>42.945537</td>\n",
       "      <td>1.406554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>France</td>\n",
       "      <td>43.604462</td>\n",
       "      <td>1.444247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Montauban</td>\n",
       "      <td>France</td>\n",
       "      <td>44.017584</td>\n",
       "      <td>1.354999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Biarritz</td>\n",
       "      <td>France</td>\n",
       "      <td>43.471144</td>\n",
       "      <td>-1.552727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Bayonne</td>\n",
       "      <td>France</td>\n",
       "      <td>43.494514</td>\n",
       "      <td>-1.473666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>La Rochelle</td>\n",
       "      <td>France</td>\n",
       "      <td>46.159732</td>\n",
       "      <td>-1.151595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location_id                          name country   latitude  longitude\n",
       "0             1             Mont Saint Michel  France  48.635954  -1.511460\n",
       "1             2                       St Malo  France  48.649518  -2.026041\n",
       "2             3                        Bayeux  France  49.276462  -0.702474\n",
       "3             4                      Le Havre  France  49.493898   0.107973\n",
       "4             5                         Rouen  France  49.440459   1.093966\n",
       "5             6                         Paris  France  48.858890   2.320041\n",
       "6             7                        Amiens  France  49.894171   2.295695\n",
       "7             8                         Lille  France  50.636565   3.063528\n",
       "8             9                    Strasbourg  France  48.584614   7.750713\n",
       "9            10  Chateau du Haut Koenigsbourg  France  48.249411   7.344320\n",
       "10           11                        Colmar  France  48.077752   7.357964\n",
       "11           12                     Eguisheim  France  48.044797   7.307962\n",
       "12           13                      Besancon  France  47.238022   6.024362\n",
       "13           14                         Dijon  France  47.321581   5.041470\n",
       "14           15                        Annecy  France  45.899235   6.128885\n",
       "15           16                      Grenoble  France  45.187560   5.735782\n",
       "16           17                          Lyon  France  45.757814   4.832011\n",
       "17           18              Gorges du Verdon  France  43.749656   6.328562\n",
       "18           19            Bormes les Mimosas  France  43.150697   6.341928\n",
       "19           20                        Cassis  France  43.214036   5.539632\n",
       "20           21                     Marseille  France  43.296174   5.369953\n",
       "21           22               Aix en Provence  France  43.529842   5.447474\n",
       "22           23                       Avignon  France  43.949249   4.805901\n",
       "23           24                          Uzes  France  44.012128   4.419672\n",
       "24           25                         Nimes  France  43.837425   4.360069\n",
       "25           26                 Aigues Mortes  France  43.566152   4.191540\n",
       "26           27      Saintes Maries de la mer  France  43.451592   4.427720\n",
       "27           28                     Collioure  France  42.525050   3.083155\n",
       "28           29                   Carcassonne  France  43.213036   2.349107\n",
       "29           30                        Ariege  France  42.945537   1.406554\n",
       "30           31                      Toulouse  France  43.604462   1.444247\n",
       "31           32                     Montauban  France  44.017584   1.354999\n",
       "32           33                      Biarritz  France  43.471144  -1.552727\n",
       "33           34                       Bayonne  France  43.494514  -1.473666\n",
       "34           35                   La Rochelle  France  46.159732  -1.151595"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read database table directly into dataframe\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_sql(select(Location.__table__), con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecfcc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "## close database connection gracefully\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kayak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
